[{"authors":["admin"],"categories":null,"content":"I am an Assistant Professor in the Department of CSE, IIT Madras. Previously, I was a postdoc in Purdue University working with Prof. Suresh Jagannathan. Before that, I did my PhD from IISc under the guidance of Prof. YN Srikant.\nI am interested in developing Verification and Analysis techniques to improve the reliability, security and efficiency of Computer Systems. In this context, I am especially interested in solving theoretical and practical verification problems arising in Concurrent and Distributed Systems, Computer Architecture, Operating Systems and Real-time Systems.\nRecently, I have worked on developing automated verification techniques for programs running under a weakly consistent memory model in the context of Distributed Replicated systems and Distributed Databases. Previously, I have also worked on developing static timing analysis techniques, focusing on the impact of the Hardware cache hierarchy on the Worst Case Execution Time of programs.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am an Assistant Professor in the Department of CSE, IIT Madras. Previously, I was a postdoc in Purdue University working with Prof. Suresh Jagannathan. Before that, I did my PhD from IISc under the guidance of Prof. YN Srikant.\nI am interested in developing Verification and Analysis techniques to improve the reliability, security and efficiency of Computer Systems. In this context, I am especially interested in solving theoretical and practical verification problems arising in Concurrent and Distributed Systems, Computer Architecture, Operating Systems and Real-time Systems.","tags":null,"title":"Kartik Nagar","type":"authors"},{"authors":null,"categories":null,"content":"Course Timings Slot D (Mon 11 AM, Tue 10 AM, Wed 9 AM, Thu 1 PM). Online.\nCourse Overview This is the standard undergraduate core course on theory of computation. The course will introduce various abstractions of computation in the form of machines with different capabilities, and also formally introduce the notion of grammars and languages. We will also show the surprising interconnections between the two seemingly different notion of machines and languages, and this in turn will lead us to some of the most fundamental questions regarding the foundations of computation: what can and cannot be computed.\nCourse Contents   Finite Automata and Regular Languages - Finite State Automata, Regular Languages, Notion of non-determinism, Subset construction, Pattern matching and regular expressions, Closure properties, Limitations, Pumping Lemma, Myhill-Nerode relations, Quotient Construction, Minimization Algorithm.\n  Pushdown Automata and Context-free Languages - Grammars and Chomsky Hierarchy, CFLs, Regular Grammars, Chomsky Normal Form, Pumping Lemma for CFLs, Inherent Ambiguity of Context-Free Languages, Cock-Younger-Kasami Algorithm, Applications to Parsing. Pushdown Automata(PDA), PDA vs CFLs. Deterministic CFLs\n  Turing Machines and Computability - Introduction to Turing Machines, Configurations, Halting vs Looping. Multi-tape Turing machines. Recursive and Recursively enumerable languages. Undecidability of Halting Problem. Reductions. Introduction to Theory of NP-completeness.\n  Grading Policy  Bi-weekly Tests (Best 5 out of 6) (Best 4 out of 5): 30%  Tests on Feb 11, 25, March 11, 25, April 8, 22, May 6   Mid-sem Exam (April 24): 20% Final Exam (May 19TBD): 70% 50%  Course Textbooks  Automata and Computability. Dexter C. Kozen. Springer Publishers. Introduction to Automata Theory, Languages, and Computation. Hopcroft, Motwani, Ullman. Pearson Publishers 3rd Edition. Introduction to the Theory of Computation. Michael Sipser. 3rd Edition.  Office Hours  Kartik Nagar (Instructor): Wednesday, 3-4 PM.  ","date":1611878400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1580256000,"objectID":"57a1e8af84817d2ad82557e57848e258","permalink":"/courses/lmc/","publishdate":"2021-01-29T00:00:00Z","relpermalink":"/courses/lmc/","section":"courses","summary":"Course Timings Slot D (Mon 11 AM, Tue 10 AM, Wed 9 AM, Thu 1 PM). Online.\nCourse Overview This is the standard undergraduate core course on theory of computation. The course will introduce various abstractions of computation in the form of machines with different capabilities, and also formally introduce the notion of grammars and languages. We will also show the surprising interconnections between the two seemingly different notion of machines and languages, and this in turn will lead us to some of the most fundamental questions regarding the foundations of computation: what can and cannot be computed.","tags":null,"title":"CS2200 - Languages, Machines and Computation","type":"docs"},{"authors":null,"categories":null,"content":"Course Timings Slot B (Mon 9 AM, Wed 1 PM, Fri 11 AM). Online.\nCourse Overview Compilers translate programs written by humans in high-level languages to programs which can be executed by machines. They are very important, heavily used and at the same time one of the most complex pieces of software. A whole range of techniques and ideas from Automata Theory, Algorithm Design, Computer Organization and Architecture, etc. are cleverly applied to create a compiler. In this course, students will learn in depth the various phases involved in the compilation process. The course will also involve implementing an actual compiler for a subset of the Java language.\nCourse Contents  Lexical Analysis and Parsing Type checking Intermediate Code Generation Register Allocation Code Generation Overview of advanced topics  Grading Policy  Theory: 60%, Lab: 40% Theory  Quiz 1 (Sep 7): 14% Quiz 2 (Oct 12): 14% Endsem (Nov 17): 30% Class Participation: 2%   Lab  5 Assignments More details on the lab webpage: https://sites.google.com/smail.iitm.ac.in/cs3300-aug-nov-2021    Course Textbooks  Compilers: Principles, Techniques, and Tools, Alfred Aho, Monica Lam, Ravi Sethi, Jeffrey D. Ullman. Addison-Wesley, 2007 Modern compiler implementation in Java, Second Edition, Andrew W. Appel, Jens Palsberg. Cambridge University Press, 2002.  ","date":1627516800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1595980800,"objectID":"ce1a60c3d533d8fd2d319cac94da367b","permalink":"/courses/compiler/","publishdate":"2021-07-29T00:00:00Z","relpermalink":"/courses/compiler/","section":"courses","summary":"Course Timings Slot B (Mon 9 AM, Wed 1 PM, Fri 11 AM). Online.\nCourse Overview Compilers translate programs written by humans in high-level languages to programs which can be executed by machines. They are very important, heavily used and at the same time one of the most complex pieces of software. A whole range of techniques and ideas from Automata Theory, Algorithm Design, Computer Organization and Architecture, etc. are cleverly applied to create a compiler.","tags":null,"title":"CS3300 - Compiler Design","type":"docs"},{"authors":null,"categories":null,"content":"Course Timings Slot F (Tue 5 PM, Wed 11 AM, Thu 9 AM, Fri 8 AM). Online.\nCourse Overview Automated Verification of programs has often been called the holy grail of computer science. While undecidable in general, over the years, a number of elegant techniques have been developed to solve this problem for several useful classes of programs. In today’s world, where the boundary between safety-critical and non safety-critical applications has become vanishingly thin and the volume and complexity of software has become staggeringly large, Automated Verification has started to gain more importance. In this course, we will go through a wide spectrum of techniques used in the domain of Automated Verification. The course will emphasise on both theory and practice, with hands-on experience of some of the tools used in this domain.\nCourse Contents   Preliminaries:SAT and SMT - Propositional Logic: Syntax and Semantics, Resolution-based SAT solving, DPLL, First-Order Logic: Syntax and Semantics, Satisfiability Modulo Theories, First Order Theories\n  Program Semantics and Specifications - Operational Semantics, Strongest Post-condition and Weakest Pre-condition, Hoare Logic\n  Automated Techniques - Abstract Interpretation, Bounded Model Checking, Predicate Abstraction, CEGAR, Property-Directed Reachability\n  Grading Policy  Assignments [3 Theory + 2 Tool]: 40% 35% Class Participation: 5% Project: 30% Endsem Exam: 30%  Course Schedule (tentative)  Assignments  Theory Assignments: Feb 7, March 7, April 4. Tool Assignments: Feb 7, March 15.   Course Project  Proposal Due on Feb 28. Project Presentation in last week of semester. Project Report Due on May 7.    Course Textbook  [BM] The Calculus of Computation: Decision Procedures with Applications to Verification. Aaron R. Bradley and Zohar Manna.  ","date":1641168000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1641168000,"objectID":"41dbdf9cfa2b521179acd5a3b68bf051","permalink":"/courses/apv-jan2022/","publishdate":"2022-01-03T00:00:00Z","relpermalink":"/courses/apv-jan2022/","section":"courses","summary":"Course Timings Slot F (Tue 5 PM, Wed 11 AM, Thu 9 AM, Fri 8 AM). Online.\nCourse Overview Automated Verification of programs has often been called the holy grail of computer science. While undecidable in general, over the years, a number of elegant techniques have been developed to solve this problem for several useful classes of programs. In today’s world, where the boundary between safety-critical and non safety-critical applications has become vanishingly thin and the volume and complexity of software has become staggeringly large, Automated Verification has started to gain more importance.","tags":null,"title":"CS5030 - Automated Program Verification","type":"docs"},{"authors":null,"categories":null,"content":"Lectures will be uploaded on the course Moodle page: https://courses.iitm.ac.in/course/view.php?id=405\nVideo Lectures Link to Google Drive Folder containing all videos: Compiler Design Lectures\n","date":1611878400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611878400,"objectID":"0e6efaa4c790551923cb35a8dfe06e7e","permalink":"/courses/compiler/lectures/","publishdate":"2021-01-29T00:00:00Z","relpermalink":"/courses/compiler/lectures/","section":"courses","summary":"Lectures will be uploaded on the course Moodle page: https://courses.iitm.ac.in/course/view.php?id=405\nVideo Lectures Link to Google Drive Folder containing all videos: Compiler Design Lectures","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":"Lectures will be uploaded on the course Moodle page: https://courses.iitm.ac.in/course/view.php?id=7129\nVideo Lectures Link to Google Drive Folder containing all videos: LMC Lectures\n","date":1611878400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611878400,"objectID":"8a3f090c5e57ab4e0e3a13c9a19414f0","permalink":"/courses/lmc/lectures/","publishdate":"2021-01-29T00:00:00Z","relpermalink":"/courses/lmc/lectures/","section":"courses","summary":"Lectures will be uploaded on the course Moodle page: https://courses.iitm.ac.in/course/view.php?id=7129\nVideo Lectures Link to Google Drive Folder containing all videos: LMC Lectures","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":"   Topic Date(s) References/Additional Reading     Introduction 18/1 Hoare\u0026rsquo;s Paper. Intro Slides of Rajeev Alur\u0026rsquo;s Course on Computer Aided Verification   Propositional Logic 19/1,20/1,21/1,27/1 BM Chapter 1   First Order Logic 28/1,1/2 BM Chapter 2   Satisfiability Modulo Theories 2/2,3/2,4/2,8/2 BM Chapter 3   SMT:Application to BMC + Z3 9/2    Operational Semantics and Verification 10/2,11/2,16/2,17/2    Strongest Post Condition 17/2,18/2     Video Lectures Link to Google Drive Folder containing all videos: APV-Jan-2022 Lectures Lectures upto 28/1 are available on the above link; rest of the lecture recordings will be directly shared through e-mail.\n","date":1599436800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599436800,"objectID":"c38d69a8121546becd024816a0145e94","permalink":"/courses/apv-jan2022/lectures/","publishdate":"2020-09-07T00:00:00Z","relpermalink":"/courses/apv-jan2022/lectures/","section":"courses","summary":"Topic Date(s) References/Additional Reading     Introduction 18/1 Hoare\u0026rsquo;s Paper. Intro Slides of Rajeev Alur\u0026rsquo;s Course on Computer Aided Verification   Propositional Logic 19/1,20/1,21/1,27/1 BM Chapter 1   First Order Logic 28/1,1/2 BM Chapter 2   Satisfiability Modulo Theories 2/2,3/2,4/2,8/2 BM Chapter 3   SMT:Application to BMC + Z3 9/2    Operational Semantics and Verification 10/2,11/2,16/2,17/2    Strongest Post Condition 17/2,18/2     Video Lectures Link to Google Drive Folder containing all videos: APV-Jan-2022 Lectures Lectures upto 28/1 are available on the above link; rest of the lecture recordings will be directly shared through e-mail.","tags":null,"title":"Lectures","type":"docs"},{"authors":["Shreesha Bhat","Kartik Nagar"],"categories":[],"content":"","date":1627362758,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627362758,"objectID":"f756dd8d38ba54345565f48418cca482","permalink":"/publication/disc21/","publishdate":"2021-07-27T10:42:38+05:30","relpermalink":"/publication/disc21/","section":"publication","summary":"We propose a framework to automate and mechanize simulation-based proofs of cutoffs for parameterized verification of distributed protocols. We propose a strategy to derive the simulation relation given the cutoff instance and encode the correctness of the simulation relation as a formula in first-order logic. We have successfully applied our approach on a number of distributed protocols.","tags":[],"title":"Brief Announcement: Automating and Mechanising Cutoff Proofs for Parameterized Verification of Distributed Protocols","type":"publication"},{"authors":["Kia Rahmani","Kartik Nagar","Benjamin Delaware","Suresh Jagannathan"],"categories":[],"content":"","date":1618444800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618444800,"objectID":"f6d506eddc9cc7d024f3b29c0d0877bd","permalink":"/publication/pldi21/","publishdate":"2021-04-15T00:00:00Z","relpermalink":"/publication/pldi21/","section":"publication","summary":"Serializability is a well-understood concurrency control mechanism that eases reasoning about highly-concurrent database programs. Unfortunately, enforcing serializability has a high-performance cost, especially on geographically distributed database clusters. Consequently, many databases allow programmers to choose when a transaction must be executed under serializability, with the expectation that transactions would only be so marked when necessary to avoid serious concurrency bugs. However, this is a significant burden to impose on developers, requiring them to (a) reason about subtle concurrent interactions among potentially interfering transactions, (b) determine when such interactions would violate desired invariants, and (c) then identify the minimum number of transactions whose executions should be serialized to prevent these violations. To mitigate this burden, in this paper we present a sound and fully automated schema refactoring procedure that transforms a program's data layout -- rather than its concurrency control logic -- to eliminate statically identified concurrency bugs, allowing more transactions to be safely executed under weaker and more performant database guarantees. Experimental results over a range of database benchmarks indicate that our approach is highly effective in eliminating concurrency bugs, with safe refactored programs showing an average of 120% higher throughput and 45% lower latency compared to the baselines.","tags":[],"title":"Repairing Serializability Bugs in Distributed Database Programs via Automated Schema Refactoring","type":"publication"},{"authors":["Vimala S","KC Sivaramakrishnan","Kartik Nagar"],"categories":[],"content":"","date":1618399607,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618399607,"objectID":"bb16dec2da62ef451d1d74f5006b002c","permalink":"/publication/papoc21/","publishdate":"2021-04-15T16:56:47+05:30","relpermalink":"/publication/papoc21/","section":"publication","summary":"","tags":[],"title":"Certified Mergeable Replicated Data Types","type":"publication"},{"authors":null,"categories":null,"content":"I am an avid reader (mostly fiction). I diligently keep track of all of my books at my Goodreads Account.\n","date":1595894400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595894400,"objectID":"dda055c1b96739b21a95ca89d07548d9","permalink":"/personal/","publishdate":"2020-07-28T00:00:00Z","relpermalink":"/personal/","section":"","summary":"I am an avid reader (mostly fiction). I diligently keep track of all of my books at my Goodreads Account.","tags":null,"title":"Personal","type":"page"},{"authors":[],"categories":[],"content":"For global-scale applications such as Amazon, Twitter, Facebook, etc. with users distributed across the world, in order to provide a uniform low-latency and always available service, the application data needs to replicated at multiple servers across the world. Such replicated systems also facilitate other useful properties such as better scalability and fault tolerance, but they are very hard to program since they offer a completely different memory model to the programmers. Since the same data at different replicas can be concurrently updated and the updates can be applied in different orders at different replicas, this can result in subtle concurrency bugs for the applications running on top of replicated systems which can be hard to find through testing-based approaches. In this project, we proposed a number of automated verification techniques to reason about correctness of programs running on top of replicated systems.\nRepresentative Publications:  Semantics, Specification and Automated Verification of Concurrent Libraries in Replicated Systems. Kartik Nagar, Prasita Mukherjee and Suresh Jagannathan. CAV 20 CLOTHO : Directed Test Generation for Weakly Consistent Database Systems. Kia Rahmani, Kartik Nagar, Benjamin Delaware and Suresh Jagannathan. OOPSLA 19. Automated Parameterized Verification of CRDTs. Kartik Nagar and Suresh Jagannathan. CAV 19. Automated Detection of Serializability Violations under Weak Consistency. Kartik Nagar and Suresh Jagannathan. CONCUR 18. Alone Together: Compositional Reasoning and Inference for Weak Isolation. Gowtham Kaki, Kartik Nagar, Mahsa Najafzadeh and Suresh Jagannathan. POPL 18.  ","date":1594166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594166400,"objectID":"55e3b6edf839458e10643d9425356d98","permalink":"/project/replicated-systems/","publishdate":"2020-07-08T00:00:00Z","relpermalink":"/project/replicated-systems/","section":"project","summary":"For global-scale applications such as Amazon, Twitter, Facebook, etc. with users distributed across the world, in order to provide a uniform low-latency and always available service, the application data needs to replicated at multiple servers across the world. Such replicated systems also facilitate other useful properties such as better scalability and fault tolerance, but they are very hard to program since they offer a completely different memory model to the programmers.","tags":[],"title":"Automated Reasoning for Replicated Systems","type":"project"},{"authors":["Kartik Nagar","Prasita Mukherjee","Suresh Jagannathan"],"categories":[],"content":"","date":1586217600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586217600,"objectID":"bcab7db049ae760d729f7b96d13edeb8","permalink":"/publication/cav20/","publishdate":"2020-04-07T15:26:22+05:30","relpermalink":"/publication/cav20/","section":"publication","summary":"Geo-replicated systems provide a number of desirable properties such as globally low latency, high availability, scalability, and built-in fault tolerance. Unfortunately, programming correct applications on top of such systems has proven to be very challenging, in large part because of the weak consistency guarantees they offer. These complexities are exacerbated when we try to adapt existing highly-performant concurrent libraries developed for shared-memory environments to this setting. The use of these libraries, developed with performance and scalability in mind, is highly desirable. But, identifying a suitable notion of correctness to check their validity under a weakly consistent execution model has not been well-studied, in large part because it is problematic to naively transplant criteria such as linearizability that has a useful interpretation in a shared-memory context to a distributed one where the cost of imposing a (logical) global ordering on all actions is prohibitive. In this paper, we tackle these issues by proposing appropriate semantics and specifications for highly-concurrent libraries in a weakly-consistent, replicated setting. We use these specifications to develop a static analysis framework that can automatically detect correctness violations of library implementations parameterized with respect to the different consistency policies provided by the underlying system. We use our framework to analyze the behavior of a number of highly non-trivial library implementations of stacks, queues, and exchangers. Our results provide the first demonstration that automated correctness checking of concurrent libraries in a weakly geo-replicated setting is both feasible and practical.","tags":["Replicated-Systems"],"title":"Semantics, Specification and Bounded Verification of Concurrent Libraries in Replicated Systems","type":"publication"},{"authors":["Kia Rahmani","Kartik Nagar","Benjamin Delaware","Suresh Jagannathan"],"categories":[],"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"a433a318d23838d7433fd153e23feb9d","permalink":"/publication/oopsla19/","publishdate":"2019-10-07T10:40:22-04:00","relpermalink":"/publication/oopsla19/","section":"publication","summary":"Relational database applications are notoriously difficult to test and debug. Concurrent execution of database transactions may violate complex structural invariants that constraint how changes to the contents of one (shared) table affect the contents of another. Simplifying the underlying concurrency model is one way to ameliorate the difficulty of understanding how concurrent accesses and updates can affect database state with respect to these sophisticated properties. Enforcing serializable execution of all transactions achieves this simplification, but it comes at a significant price in performance, especially at scale, where database state is often replicated to improve latency and availability. To address these challenges, this paper presents a novel testing framework for detecting serializability violations in (SQL) database-backed Java applications executing on weakly-consistent storage systems. We manifest our approach in a tool named CLOTHO, that combines a static analyzer and a model checker to generate abstract executions, discover serializability violations in these executions, and translate them back into concrete test inputs suitable for deployment in a test environment. To the best of our knowledge, CLOTHO is the first automated test generation facility for identifying serializability anomalies of Java applications intended to operate in geo-replicated distributed environments. An experimental evaluation on a set of industry-standard benchmarks demonstrates the utility of our approach.","tags":[],"title":"CLOTHO : Directed Test Generation for Weakly Consistent Database Systems","type":"publication"},{"authors":["Kartik Nagar","Suresh Jagannathan"],"categories":[],"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"fb5ba9ad462852ba05ea03291439ae08","permalink":"/publication/cav19/","publishdate":"2019-10-04T18:47:18-04:00","relpermalink":"/publication/cav19/","section":"publication","summary":"Maintaining multiple replicas of data is crucial to achieving scalability, availability and low latency in distributed applications. Conflict-free Replicated Data Types (CRDTs) are important building blocks in this domain because they are designed to operate correctly under the myriad behaviors possible in a weakly-consistent distributed setting. Because of the possibility of concurrent updates to the same object at different replicas, and the absence of any ordering guarantees on these updates, convergence is an important correctness criterion for CRDTs. This property asserts that two replicas which receive the same set of updates (in any order) must nonetheless converge to the same state. One way to prove that operations on a CRDT converge is to show that they commute since commutative actions by definition behave the same regardless of the order in which they execute. In this paper, we present a framework for automatically verifying convergence of CRDTs under different weak-consistency policies. Surprisingly, depending upon the consistency policy supported by the underlying system, we show that not all operations of a CRDT need to commute to achieve convergence. We develop a proof rule parameterized by a consistency specification based on the concepts of commutativity modulo consistency policy and non-interference to commutativity. We describe the design and implementation of a verification engine equipped with this rule and show how it can be used to provide the first automated convergence proofs for a number of challenging CRDTs, including sets, lists, and graphs.","tags":["Replicated-Systems"],"title":"Automated Parametrized Verification of CRDTs","type":"publication"},{"authors":["Kartik Nagar","Suresh Jagannathan"],"categories":[],"content":"","date":1533081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533081600,"objectID":"9fafae8cd8a5b2d37f45f29aabebb687","permalink":"/publication/concur18/","publishdate":"2019-10-04T18:42:01-04:00","relpermalink":"/publication/concur18/","section":"publication","summary":"While a number of weak consistency mechanisms have been developed in recent years to improve performance and ensure availability in distributed, replicated systems, ensuring the correctness of transactional applications running on top of such systems remains a difficult and important problem. Serializability is a well-understood correctness criterion for transactional programs; understanding whether applications are serializable when executed in a weakly-consistent environment, however remains a challenging exercise. In this work, we combine a dependency graph-based characterization of serializability and leverage the framework of abstract executions to develop a fully-automated approach for statically finding bounded serializability violations under any weak consistency model. We reduce the problem of serializability to satisfiability of a formula in First-Order Logic (FOL), which allows us to harness the power of existing SMT solvers. We provide rules to automatically construct the FOL encoding from programs written in SQL (allowing loops and conditionals) and express consistency specifications as FOL formula. In addition to detecting bounded serializability violations, we also provide two orthogonal schemes to reason about unbounded executions by providing sufficient conditions (again, in the form of FOL formulae) whose satisfiability implies the absence of anomalies in any arbitrary execution. We have applied the proposed technique on TPC-C, a real-world database program with complex application logic, and were able to discover anomalies under Parallel Snapshot Isolation (PSI), and verify serializability for unbounded executions under Snapshot Isolation (SI), two consistency mechanisms substantially weaker than serializability.","tags":[],"title":"Automated Detection of Serializability Violations under Weak Consistency","type":"publication"},{"authors":["Gowtham Kaki","Kartik Nagar","Mahsa Najafzadeh","Suresh Jagannathan"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"620964e755b5f17f19bb4874b687f13e","permalink":"/publication/popl18/","publishdate":"2019-10-04T18:21:41-04:00","relpermalink":"/publication/popl18/","section":"publication","summary":"Serializability is a well-understood correctness criterion that simplifies reasoning about the behavior of concurrent transactions by ensuring they are isolated from each other while they execute. However, enforcing serializable isolation comes at a steep cost in performance because it necessarily restricts opportunities to exploit concurrency even when such opportunities would not violate application-specific invariants. As a result, database systems in practice support, and often encourage, developers to implement transactions using weaker alternatives. These alternatives break the strong isolation guarantees offered by serializable transactions to permit greater concurrency. Unfortunately, the semantics of weak isolation is poorly understood, and usually explained only informally in terms of low-level implementation artifacts. Consequently, verifying high-level correctness properties in such environments remains a challenging problem. To address this issue, we present a novel program logic that enables compositional reasoning about the behavior of concurrently executing weakly-isolated transactions. Recognizing that the proof burden necessary to use this logic may dissuade application developers, we also describe an inference procedure based on this foundation that ascertains the weakest isolation level that still guarantees the safety of high-level consistency assertions associated with such transactions. The key to effective inference is the observation that weakly-isolated transactions can be viewed as functional (monadic) computations over an abstract database state, allowing us to treat their operations as state transformers over the database. This interpretation enables automated verification using off-the-shelf SMT solvers. Our development is parametric over a transaction’s specific isolation semantics, allowing it to be applicable over a range of concurrency control mechanisms. Case studies and experiments on real-world applications (written in an embedded DSL in OCaml) demonstrate the utility of our approach, and provide strong evidence that automated verification of weakly-isolated transactions can be placed on the same formal footing as their strongly-isolated serializable counterparts.","tags":[],"title":"Alone together: Compositional Reasoning and Inference for Weak Isolation","type":"publication"},{"authors":["Kartik Nagar","Y N Srikant"],"categories":[],"content":"","date":1501545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501545600,"objectID":"73cf65f308d78fe96a88f0ce00f34e1b","permalink":"/publication/tecs17/","publishdate":"2019-10-04T18:17:53-04:00","relpermalink":"/publication/tecs17/","section":"publication","summary":"Worst-Case Execution Time (WCET) is an important metric for programs running on real-time systems, and finding precise estimates of a program’s WCET is crucial to avoid wastage of hardware resources and to improve the schedulability of task sets. Caches have a major impact on a program’s execution time, and accurate estimation of a program’s cache behavior can lead to significant reduction in its estimated WCET. The traditional approach to cache analysis generally targets the worst-case cache behavior of individual cache accesses and provides a safe hit-miss classification for every individual access. In this work, we show that these classifications are not sufficient to precisely capture cache behavior, since they apply to individual accesses, and often, more precise predictions can be made about groups of accesses. Further, memory accesses inside loops may show the worst-case behavior only for a subset of the iteration space. In order to predict such behavior in a scalable fashion, we use the fact that the cache behavior of an access mostly depends only on the memory accesses made in the immediate vicinity, and hence we analyze a small, fixed-size neighborhood of every access with complete precision and summarize the resulting information in the form of cache miss paths. A variety of analyses are then performed on the cache miss paths to make precise predictions about cache behavior. We also demonstrate precision issues in Abstract Interpretation-based Must and Persistence cache analysis that can be easily solved using cache miss paths. Experimental results over a wide range of benchmarks demonstrate precision improvement in WCET of multipath programs over previous approaches, and we also show how to integrate our approach with other microarchitectural analysis such as pipeline analysis.","tags":[],"title":"Refining Cache Behaviour Prediction using Cache Miss Paths","type":"publication"},{"authors":["Kartik Nagar","Y N Srikant"],"categories":[],"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"284dffaebd4f3a1787f4ed6bd5af4858","permalink":"/publication/tecs16/","publishdate":"2019-10-04T18:11:22-04:00","relpermalink":"/publication/tecs16/","section":"publication","summary":"Real-time systems require a safe and precise estimate of the worst-case execution time (WCET) of programs. In multicore architectures, the precision of a program’s WCET estimate highly depends on the precision of its predicted shared cache behavior. Prediction of shared cache behavior is difficult due to the uncertain timing of interfering shared cache accesses made by programs running on other cores. Given the assignment of programs to cores, the worst-case interference placement (WCIP) technique tries to find the worst-case timing of interfering accesses, which would cause the maximum number of cache misses on the worst case path of the program, to determine its WCET. Although WCIP generates highly precise WCET estimates, the current ILP-based approach is also known to have very high analysis time. In this work, we investigate the WCIP problem in detail and determine its source of hardness. We show that performing WCIP is an NP-hard problem by reducing the 0-1 knapsack problem. We use this observation to make simplifying assumptions, which make the WCIP problem tractable, and we propose an approximate greedy technique for WCIP, whose time complexity is linear in the size of the program. We perform extensive experiments to show that the assumptions do not affect the precision of WCIP but result in significant reduction of analysis time.","tags":[],"title":"Fast and Precise Worst Case Interference Placement for Shared Cache Analysis","type":"publication"},{"authors":[],"categories":[],"content":"In Real-time systems, e.g. automobiles, aircrafts, space shuttles, robots, etc. programs are executed in response to external stimuli and must finish their execution before fixed deadlines to ensure correct behavior. Hence, Worst Case Execution Time (WCET) becomes a very important correctness criterion for programs running on real-time systems. In this project, we proposed static analysis techniques to determine the WCET of programs, chiefly focusing on the impact of caches on timing of programs.\nRepresentative Publications   Refining Cache Behaviour Prediction using Cache Miss Paths. Kartik Nagar and YN Srikant. TECS 17\n  Fast and Precise Worst Case Interference Placement for Shared Cache Analysis. Kartik Nagar and YN Srikant. TECS 16\n  Path-sensitive Cache Analysis using Cache Miss Paths. Kartik Nagar and YN Srikant. VMCAI 15\n  Precise Shared Cache Analysis using Optimal Interference Placement. Kartik Nagar and YN Srikant. RTAS 14\n  Interdependent Cache Analyses for better Precision and Safety. Kartik Nagar and YN Srikant. MEMOCODE 12\n  ","date":1464739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1464739200,"objectID":"9a88d71086640fad1f8a9e7ed70c78a7","permalink":"/project/timing-analysis/","publishdate":"2016-06-01T00:00:00Z","relpermalink":"/project/timing-analysis/","section":"project","summary":"In Real-time systems, e.g. automobiles, aircrafts, space shuttles, robots, etc. programs are executed in response to external stimuli and must finish their execution before fixed deadlines to ensure correct behavior. Hence, Worst Case Execution Time (WCET) becomes a very important correctness criterion for programs running on real-time systems. In this project, we proposed static analysis techniques to determine the WCET of programs, chiefly focusing on the impact of caches on timing of programs.","tags":[],"title":"Timing Analysis for Real-time Systems","type":"project"},{"authors":["Kartik Nagar","Y N Srikant"],"categories":[],"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"84fb697057392c0a321983d93afbdae5","permalink":"/publication/vmcai15/","publishdate":"2019-10-04T18:15:00-04:00","relpermalink":"/publication/vmcai15/","section":"publication","summary":"Cache analysis plays a very important role in obtaining precise Worst Case Execution Time (WCET) estimates of programs for real-time systems. While Abstract Interpretation based approaches are almost universally used for cache analysis, they fail to take advantage of its unique requirement: it is not necessary to find the guaranteed cache behavior that holds across all executions of a program. We only need the cache behavior along one particular program path, which is the path with the maximum execution time. In this work, we introduce the concept of cache miss paths, which allows us to use the worst-case path information to improve the precision of AI-based cache analysis. We use Abstract Interpretation to determine the cache miss paths, and then integrate them in the IPET formulation. An added advantage is that this further allows us to use infeasible path information for cache analysis. Experimentally, our approach gives more precise WCETs as compared to AI-based cache analysis, and we also provide techniques to trade-off analysis time with precision to provide scalability.","tags":[],"title":"Path-sensitive Cache Analysis using Cache Miss Paths","type":"publication"},{"authors":["Kartik Nagar","Y N Srikant"],"categories":[],"content":"","date":1396310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396310400,"objectID":"ecac2f55994687421b748a09b1d33a80","permalink":"/publication/rtas14/","publishdate":"2019-10-04T18:05:26-04:00","relpermalink":"/publication/rtas14/","section":"publication","summary":"Determining the Worst Case Execution Time (WCET) of programs running on a multi-core architecture is a challenging problem, that is hampering the use of multi-cores in real-time systems. The highly imprecise WCET estimates obtained using the current state-of-the-art analyses has prompted research in the direction of making the multi-core architecture itself more estimation-friendly, but there has been little effort to make the WCET analysis more precise. The main difficulty in analyzing programs running on multi-core architectures arises from the fact that interferences to shared resources (such as shared cache) from other cores can occur at any time. Hence, to perform safe micro-architectural analysis, current approaches assume that all interferences occur at all times, which results in significantly imprecise analysis WCET estimates. However, since we are interested in the WCET, we can instead assume that the interferences will come at the worst possible program points, causing maximum increase in the execution time. In our work, we formulate an ILP problem to determine these worst case interference points, from the perspective of a shared cache, and determine the WCET by assuming that the interferences come at those program points. Our approach provides an average precision improvement of 25.63% over earlier analysis for benchmarks which perform a reasonable number of accesses to the shared cache.","tags":[],"title":"Precise Shared Cache Analysis using Optimal Interference Placement","type":"publication"},{"authors":["Kartik Nagar","Y N Srikant"],"categories":[],"content":"","date":1341100800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341100800,"objectID":"a5d5e2a677fd22595c24adc5d13b34db","permalink":"/publication/memocode-12/","publishdate":"2012-07-01T00:00:00Z","relpermalink":"/publication/memocode-12/","section":"publication","summary":"One of the challenges for accurately estimating Worst Case Execution Time(WCET) of executables is to accurately predict their cache behavior. Various techniques have been developed to predict the cache contents at different program points to estimate the execution time of memory-accessing instructions. One of the most widely used techniques is Abstract Interpretation based Must Analysis, which determines the cache blocks guaranteed to be present in the cache, and hence provides safe estimation of cache hits and misses. However, Must Analysis is highly imprecise, and platforms using Must Analysis have been known to produce blown-up WCET estimates. In our work, we propose to use May Analysis to assist the Must Analysis cache update and make it more precise. We prove the safety of our approach as well as provide examples where our Improved Must Analysis provides better precision. Further, we also detect a serious flaw in the original Persistence Analysis, and use Must and May Analysis to assist the Persistence Analysis cache update, to make it safe and more precise than the known solutions to the problem. Finally, we propose an improvement in the original May Analysis, to make it more precise, especially for Data Cache Analysis.","tags":[],"title":"Interdependent Cache Analyses for better precision and safety","type":"publication"}]